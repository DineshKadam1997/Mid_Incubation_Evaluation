{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageDraw\nimport os\nimport math\n\n# Function to generate a shape image with a specific color\ndef generate_shape_image(width, height, shape, color):\n    image = Image.new(\"RGB\", (width, height), \"white\")\n    draw = ImageDraw.Draw(image)\n    \n    # Draw the shape with the corresponding color\n    if shape == \"rectangle\":\n        draw.rectangle([10, 20, width-10, height-10], fill=color)\n    elif shape == \"square\":\n        draw.rectangle([10, 10, width-10, height-10], fill=color)\n    elif shape == \"triangle\":\n        draw.polygon([(width//2, 10), (10, height-10), (width-10, height-10)], fill=color)\n    elif shape == \"pentagon\":\n        side_length = width // 3\n        center = (width // 2, height // 2)\n        points = []\n        for i in range(5):\n            angle = math.radians(360 / 5 * i - 90)\n            x = center[0] + side_length * math.cos(angle)\n            y = center[1] + side_length * math.sin(angle)\n            points.append((x, y))\n        draw.polygon(points, fill=color)\n    elif shape == \"trapezium\":\n        draw.polygon([(20, 10), (width-20, 10), (width-40, height-10), (40, height-10)], fill=color)\n    \n    return image\n\n# Function to save images to a directory\ndef save_images(output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Define colors for each shape\n    shape_colors = {\n        \"rectangle\": \"red\",\n        \"square\": \"green\",\n        \"triangle\": \"blue\",\n        \"pentagon\": \"orange\",\n        \"trapezium\": \"purple\",\n    }\n    \n    for i, (shape, color) in enumerate(shape_colors.items()):\n        image = generate_shape_image(100, 100, shape, color)\n        image_path = os.path.join(output_dir, f\"image_{i}.png\")\n        image.save(image_path)\n\n# Generate and save 6 images to a directory named \"shapes_dataset\"\nsave_images(\"/kaggle/working/shapes_dataset4\")","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:45:47.711585Z","iopub.execute_input":"2024-03-14T14:45:47.711992Z","iopub.status.idle":"2024-03-14T14:45:47.732904Z","shell.execute_reply.started":"2024-03-14T14:45:47.711961Z","shell.execute_reply":"2024-03-14T14:45:47.731563Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport os\n\n# Function to convert colored images to grayscale\ndef convert_to_grayscale(input_dir, output_dir):\n    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n    for file_name in os.listdir(input_dir):\n        if file_name.endswith('.png'):\n            # Load the image\n            image_path = os.path.join(input_dir, file_name)\n            image = Image.open(image_path)\n            \n            # Convert to grayscale\n            grayscale_image = image.convert('L')\n            \n            # Save the grayscale image\n            output_path = os.path.join(output_dir, file_name)\n            grayscale_image.save(output_path)\n\n# Convert colored images in the 'colored_dataset' directory to grayscale and save them to a new directory\nconvert_to_grayscale('/kaggle/working/shapes_dataset4', '/kaggle/working/grayscale_dataset4')","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:45:50.925969Z","iopub.execute_input":"2024-03-14T14:45:50.926418Z","iopub.status.idle":"2024-03-14T14:45:50.939429Z","shell.execute_reply.started":"2024-03-14T14:45:50.926384Z","shell.execute_reply":"2024-03-14T14:45:50.938148Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\n# Function to preprocess image before edge detection\ndef preprocess_image(image):\n    # Apply thresholding to create binary image\n    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n    \n    # Apply morphological closing to fill gaps and smooth edges\n    kernel = np.ones((5, 5), np.uint8)\n    closed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n    \n    return closed_image\n\n# Function to perform edge detection on grayscale images\ndef apply_edge_detection(input_dir, output_dir):\n    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n    for file_name in os.listdir(input_dir):\n        if file_name.endswith('.png'):\n            # Load the grayscale image\n            image_path = os.path.join(input_dir, file_name)\n            grayscale_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n            \n            # Preprocess image\n            processed_image = preprocess_image(grayscale_image)\n            \n            # Apply edge detection using Canny\n            edges = cv2.Canny(processed_image, 100, 200)  # Adjust the threshold values as needed\n            \n            # Save the edge-detected image\n            output_path = os.path.join(output_dir, file_name)\n            cv2.imwrite(output_path, edges)\n\n# Apply edge detection to grayscale images in the 'grayscale_dataset' directory and save them to a new directory\napply_edge_detection('/kaggle/working/grayscale_dataset4', '/kaggle/working/edge_detected_dataset4')","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:45:53.934009Z","iopub.execute_input":"2024-03-14T14:45:53.934973Z","iopub.status.idle":"2024-03-14T14:45:53.951453Z","shell.execute_reply.started":"2024-03-14T14:45:53.934931Z","shell.execute_reply":"2024-03-14T14:45:53.950049Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\n# Define input and output directories\ninput_dir = '/kaggle/working/shapes_dataset4'\noutput_dir = '/kaggle/working/rotated_dataset4'\n\n# Define rotation angles\nangles = [-45, -30, -15, 15, 30, 45]\n\n# Function to rotate images and save them to the output directory\ndef rotate_images(input_dir, output_dir, angles):\n    os.makedirs(output_dir, exist_ok=True)\n    for file_name in os.listdir(input_dir):\n        if file_name.endswith('.png'):\n            image_path = os.path.join(input_dir, file_name)\n            image = cv2.imread(image_path)\n            for angle in angles:\n                rotated_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n                output_path = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}_{angle}.png\")\n                cv2.imwrite(output_path, rotated_image)\n\n# Rotate images in the input directory and save them to the output directory\nrotate_images(input_dir, output_dir, angles)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:45:57.069506Z","iopub.execute_input":"2024-03-14T14:45:57.069926Z","iopub.status.idle":"2024-03-14T14:45:57.089600Z","shell.execute_reply.started":"2024-03-14T14:45:57.069893Z","shell.execute_reply":"2024-03-14T14:45:57.088465Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Define input and output directories\ninput_dir = '/kaggle/working/rotated_dataset4'\n\n# Load images and corresponding rotation angles\nimages = []\nangles = []\n\nfor file_name in os.listdir(input_dir):\n    if file_name.endswith('.png'):\n        image_path = os.path.join(input_dir, file_name)\n        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(100, 100))\n        image_array = tf.keras.preprocessing.image.img_to_array(image)\n        images.append(image_array)\n        angle = int(file_name.split('_')[-1].split('.')[0])\n        angles.append(angle)\n\nimages = np.array(images)\nangles = np.array(angles)\n\n# Normalize images\nimages = images / 255.0\n\n# Define the CNN model\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='mean_squared_error')\n\n# Train the model\nmodel.fit(images, angles, epochs=10, batch_size=32, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:31:41.788715Z","iopub.execute_input":"2024-03-14T14:31:41.789157Z","iopub.status.idle":"2024-03-14T14:31:46.907027Z","shell.execute_reply.started":"2024-03-14T14:31:41.789120Z","shell.execute_reply":"2024-03-14T14:31:46.906122Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 899.4020 - val_loss: 1899.4974\nEpoch 2/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 870.4240 - val_loss: 2149.3838\nEpoch 3/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 873.3550 - val_loss: 1934.5177\nEpoch 4/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 859.5173 - val_loss: 1893.6219\nEpoch 5/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 859.8173 - val_loss: 2004.0947\nEpoch 6/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 851.8667 - val_loss: 2274.7463\nEpoch 7/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 855.4915 - val_loss: 2187.4717\nEpoch 8/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 848.6492 - val_loss: 2087.1472\nEpoch 9/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 848.1973 - val_loss: 2073.3955\nEpoch 10/10\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 849.1132 - val_loss: 2141.7854\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79e43bfe9bd0>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Define input and output directories\ninput_dir = '/kaggle/working/grayscale_dataset4'\noutput_dir = '/kaggle/working/edge_detected_dataset4'\n\n# Load images and corresponding edge-detected images\nimages = []\nedges = []\n\nfor file_name in os.listdir(input_dir):\n    if file_name.endswith('.png'):\n        image_path = os.path.join(input_dir, file_name)\n        edge_path = os.path.join(output_dir, file_name)\n        \n        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(100, 100), color_mode='grayscale')\n        edge = tf.keras.preprocessing.image.load_img(edge_path, target_size=(100, 100), color_mode='grayscale')\n        \n        image_array = tf.keras.preprocessing.image.img_to_array(image)\n        edge_array = tf.keras.preprocessing.image.img_to_array(edge)\n        \n        images.append(image_array)\n        edges.append(edge_array)\n\nimages = np.array(images)\nedges = np.array(edges)\n\n# Normalize images\nimages = images / 255.0\n\n# Define the CNN model\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(100, 100, 1)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n    layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')  # Output layer with sigmoid activation for edge detection\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(images, edges, epochs=10, batch_size=32, validation_split=0.2)\n\n     ","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:47:19.709370Z","iopub.execute_input":"2024-03-14T14:47:19.709849Z","iopub.status.idle":"2024-03-14T14:47:19.983951Z","shell.execute_reply.started":"2024-03-14T14:47:19.709812Z","shell.execute_reply":"2024-03-14T14:47:19.982650Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 50\u001b[0m\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     46\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     47\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:663\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[0;32m--> 663\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    666\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    667\u001b[0m         )\n\u001b[1;32m    669\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[1;32m    670\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m )\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n","\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 100, 100, 1), output.shape=(None, 25, 25, 1)"],"ename":"ValueError","evalue":"Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 100, 100, 1), output.shape=(None, 25, 25, 1)","output_type":"error"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\n# Function to preprocess image before edge detection\ndef preprocess_image(image):\n    # Apply thresholding to create binary image\n    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n    \n    # Apply morphological closing to fill gaps and smooth edges\n    kernel = np.ones((5, 5), np.uint8)\n    closed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n    \n    return closed_image\n\n# Function to perform edge detection on grayscale images\ndef apply_edge_detection(input_dir, output_dir):\n    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n    for file_name in os.listdir(input_dir):\n        if file_name.endswith('.png'):\n            # Load the grayscale image\n            image_path = os.path.join(input_dir, file_name)\n            grayscale_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n            \n            # Preprocess image\n            processed_image = preprocess_image(grayscale_image)\n            \n            # Apply edge detection using Canny\n            edges = cv2.Canny(processed_image, 100, 200)  # Adjust the threshold values as needed\n            \n            # Save the edge-detected image\n            output_path = os.path.join(output_dir, file_name)\n            cv2.imwrite(output_path, edges)\n\n# Apply edge detection to grayscale images in the 'grayscale_dataset' directory and save them to a new directory\napply_edge_detection('/kaggle/working/grayscale_dataset3', '/kaggle/working/edge_detected_dataset4')","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:49:26.776663Z","iopub.execute_input":"2024-03-14T14:49:26.777158Z","iopub.status.idle":"2024-03-14T14:49:26.802480Z","shell.execute_reply.started":"2024-03-14T14:49:26.777122Z","shell.execute_reply":"2024-03-14T14:49:26.800175Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}